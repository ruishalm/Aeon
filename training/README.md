# ğŸ¯ RESUMO: SUA ESTRATÃ‰GIA DE TREINAMENTO

## VocÃª tem 2 modos no Aeon:
- **Online (Groq na nuvem)** â†’ Melhor qualidade, mas precisa internet
- **Offline (Ollama local)** â†’ RÃ¡pido, privado, sem internet

**COISA BOA:** VocÃª pode treinar OS DOIS com os mesmos dados! ğŸ‰

---

## Fluxo RÃ¡pido (5 passos)

```
1. COLETAR dados
   â””â”€ Copie logs (ChatGPT, Claude, Discord, Aeon) para: training/raw_logs/

2. CONVERTER logs
   â””â”€ python converter.py --source raw_logs/ --jsonl --profile

3. EXTRAIR PADRÃ•ES (seu estilo)
   â””â”€ python extrair_padroes.py processed/dados_combined.jsonl

4. TREINAR modelo
   â””â”€ Escolha 1 (Groq / Ollama / Unsloth) e rode script

5. INTEGRAR em Aeon
   â””â”€ Coloque modelo novo em core/brain.py
```

---

## O que cada Script Faz

### `converter.py` â­
**Transforma qualquer log em formato VOCÃŠ/AEON**

Suporta:
- âœ… ChatGPT JSON
- âœ… Claude JSON  
- âœ… Discord JSON
- âœ… Logs simples (.txt)
- âœ… Logs genÃ©ricos

```bash
python converter.py --source raw_logs/ --jsonl --profile
```

**Output:**
- `processed/dados_combined.txt` (VOCÃŠ/AEON)
- `processed/dados_combined.jsonl` (pronto para treinar)
- Console mostra anÃ¡lise de seus padrÃµes

---

### `extrair_padroes.py` â­
**Detecta como vocÃª fala e gera system_prompt customizado**

Analisa:
- GÃ­rias que vocÃª usa (rodar, crashar, etc)
- ExpressÃµes favoritas (tipo, nÃ©, etc)
- Seu tom (entusiasmado? Investigativo?)
- Estrutura (muitas perguntas? Muitos comandos?)
- Emojis (qual frequÃªncia?)

```bash
python extrair_padroes.py processed/dados_combined.jsonl
```

**Output:**
- `CUSTOM_SYSTEM_PROMPT.md` (seu perfil em format de prompt)

Depois vocÃª copia esse prompt e coloca em `core/brain.py` â†’ Aeon fala igual vocÃª!

---

## OPÃ‡ÃƒO 1: Groq (Nuvem)

```
VOCÃŠ TREINA (20-30 min via API) â†’ MODELO FICA NA GROQ
â†“
Integra em core/brain.py (sem instalar nada)
â†“
Aeon chama Groq com modelo personalizado
```

**Vantagens:**
- âš¡ RÃ¡pido
- â˜ï¸ Na nuvem (sem hardware local)
- ğŸ”„ FÃ¡cil atualizar

**Passos:**
```bash
python converter.py --source raw_logs/ --jsonl
# Script de fine-tune Groq (vou providenciar)
# Integrar em core/brain.py
```

---

## OPÃ‡ÃƒO 2: Ollama (Local + LoRA)

```
VOCÃŠ TREINA (1-2 horas) â†’ MODELO FICA NO SEU PC
â†“
Rodando localmente em Ollama
â†“
Aeon chama modelo local automaticamente
```

**Vantagens:**
- ğŸ  Privado (nada sai do PC)
- ğŸ“± Offline (sem internet)
- ğŸ”§ CustomizÃ¡vel ao mÃ¡ximo

**Passos:**
```bash
pip install llama-factory
python converter.py --source raw_logs/ --jsonl
# Configurar e rodar fine-tune local
# Exportar para Ollama
# Integrar em core/brain.py
```

---

## OPÃ‡ÃƒO 3: Unsloth (Mais RÃ¡pido Ainda)

```
VOCÃŠ TREINA (15-30 min) â†’ MODELO PRONTO
â†“
Pode virar LoRA (Ollama) ou arquivo completo
â†“
Integra onde quiser (Groq, Ollama, local)
```

**Vantagens:**
- âš¡âš¡ Super rÃ¡pido
- ğŸ¯ Melhor qualidade
- ğŸ”— CompatÃ­vel com Groq e Ollama

**Passos:**
```bash
pip install unsloth
python converter.py --source raw_logs/ --jsonl
# Script Unsloth (vou providenciar)
# Exportar modelo
# Integrar em core/brain.py
```

---

## ComparaÃ§Ã£o RÃ¡pida

| Aspecto | Groq | Ollama | Unsloth |
|---------|------|--------|---------|
| **Tempo** | 20-30 min | 1-2 horas | 15-30 min â­ |
| **Hardware** | Cloud | Local | Local + GPU |
| **Privacidade** | â˜ï¸ Cloud | ğŸ  Total | ğŸ  Total |
| **FÃ¡cil** | âœ… Sim | âš ï¸ MÃ©dio | âœ… Sim |
| **Custo** | ğŸ’° API | GrÃ¡tis | GrÃ¡tis |
| **Offline** | âŒ NÃ£o | âœ… Sim | âœ… Sim |

---

## ğŸš€ Comece AGORA!

### Passo 1: Converter Seus Logs
```bash
cd d:\Dev\Aeon\Aeon\training
python converter.py --source raw_logs/ --jsonl --profile
```

Se houver erro, coloque logs em `raw_logs/` (veja `raw_logs/README.md`)

### Passo 2: Extrair Seu Perfil
```bash
python extrair_padroes.py processed/dados_combined.jsonl
```

Abra `CUSTOM_SYSTEM_PROMPT.md` e veja seu perfil detectado!

### Passo 3: Escolha 1 MÃ©todo
- **Groq:** Script que vou fornecer
- **Ollama:** Vou fornecer config + script
- **Unsloth:** Vou fornecer notebook + script

### Passo 4: Integrate em core/brain.py
Cole seu novo modelo no `pensar()`

### Passo 5: Teste!
```bash
python main.py
"OlÃ¡ Aeon!"
# Esperado: Resposta em SEU ESTILO! ğŸ¯
```

---

## ğŸ“š Arquivos Complementares

- âœ… **TRAINING_GUIDE.md** - Guia super detalhado com exemplos
- âœ… **converter.py** - Converte logs automaticamente
- âœ… **extrair_padroes.py** - Detecta seus padrÃµes
- âœ… **raw_logs/README.md** - Como exportar de cada plataforma

---

## â“ TL;DR (Muito Longo; NÃ£o Li)

1. **Coleta:** Logs em `training/raw_logs/`
2. **Conversor:** `python converter.py --source raw_logs/ --jsonl --profile`
3. **PadrÃµes:** `python extrair_padroes.py processed/dados_combined.jsonl`
4. **Treina:** Escolha Groq / Ollama / Unsloth
5. **Integra:** Cole modelo em `core/brain.py`
6. **Testa:** `python main.py` e fale com Aeon

---

**Vamos fazer isso?** ğŸš€
